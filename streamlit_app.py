import streamlit as st
import pandas as pd

# M√≥dulos del proyecto
from scoring import RULES, SECTION_LIMITS, sum_with_section_caps
from parsers import extract_text, detect_counts, PDFSupportMissing
from report import build_docx_report  # si no lo us√°s, pod√©s comentar estas 2 l√≠neas

# ---------------------------------------------------------------------
# Configuraci√≥n de p√°gina
# ---------------------------------------------------------------------
st.set_page_config(
    page_title="Categorizador Docente en Investigaci√≥n",
    page_icon="üìä",
    layout="wide",
)

st.title("üìä Categorizador Docente en Investigaci√≥n")
st.caption("Lee CV en .docx/.pdf/.txt y aplica el valorador con topes por √≠tem y secci√≥n.")

with st.expander("üìã Instrucciones", expanded=True):
    st.markdown(
        """
        1) Sub√≠ tu CV (.docx/.pdf/.txt). Recomendado: **.docx**.  
        2) La app detecta cantidades con expresiones regulares (heur√≠sticas).  
        3) Se aplican topes por √≠tem, sub-secci√≥n y secci√≥n.  
        4) Pod√©s descargar el **desglose en CSV** o un **informe .docx**.  

        **Nota:** archivos **.doc** (Word 97-2003) no est√°n soportados. Convertir a .docx o PDF.
        """
    )

# ---------------------------------------------------------------------
# C√°lculo de puntajes a partir de conteos detectados
# ---------------------------------------------------------------------
def compute_scores(counts: dict):
    rows = []
    section_totals = {}

    for key, rule in RULES.items():
        units = counts.get(key, 0)
        raw_points = units * rule.points_per_unit
        capped_points = min(raw_points, rule.max_points)
        section = key.split(":")[0]

        section_totals[section] = section_totals.get(section, 0.0) + capped_points

        rows.append({
            "Clave": key,
            "Secci√≥n": section,
            "√çtem": rule.label,
            "Unidades detectadas": units,
            "Puntos por unidad": rule.points_per_unit,
            "Tope √≠tem": rule.max_points,
            "Puntos (tope √≠tem)": capped_points,
        })

    # Topes por secci√≥n (si est√°n definidos)
    for sec, limit in SECTION_LIMITS.items():
        if sec in section_totals:
            section_totals[sec] = min(section_totals[sec], limit)

    totals = sum_with_section_caps(section_totals)
    return pd.DataFrame(rows), totals

# ---------------------------------------------------------------------
# Uploader (si no hay archivo, frenamos aqu√≠)
# ---------------------------------------------------------------------
st.subheader("Sub√≠ tu CV")
uploaded = st.file_uploader(
    label="Arrastr√° y solt√° o hac√© clic en **Browse files**",
    type=("docx", "pdf", "txt"),
    accept_multiple_files=False,
    key="cv_uploader",
)
if uploaded is None:
    st.info("üëâ Eleg√≠ un archivo (.docx recomendado).")
    st.stop()

# ---------------------------------------------------------------------
# Procesamiento del archivo (compatible con parsers.extract_text(bytes, filename))
# ---------------------------------------------------------------------
try:
    file_bytes = bytes(uploaded.getbuffer())
    filename = uploaded.name

    # NUEVO: el parser espera (bytes, filename) y devuelve texto normalizado
    text = extract_text(file_bytes, filename)

    # Deducimos el ‚Äúkind‚Äù solo para mostrar
    ext = (filename.split(".")[-1] or "").lower()
    kind = ext if ext in ("docx", "pdf", "txt") else "archivo"

    st.success(f"Archivo le√≠do como **{kind.upper()}** ‚Äì longitud: {len(text)} caracteres")

    # Detectores + puntajes
    counts = detect_counts(text)
    df_items, totals = compute_scores(counts)

    # ------------------ UI de resultados ------------------
    st.subheader("Desglose por √≠tem")
    st.dataframe(df_items, use_container_width=True)

    st.subheader("Subtotales por secci√≥n (con topes)")
    show_keys = [
        "2:Formacion_total",
        "3:Cargos_total",
        "4:CyT_total",
        "5:Producciones_total",
        "6:Otros_total",
        "TOTAL_GENERAL",
    ]
    subt = pd.DataFrame([(k, totals.get(k, 0)) for k in show_keys], columns=["Secci√≥n", "Puntaje"])
    st.table(subt)

    # Descarga CSV
    csv = df_items.to_csv(index=False).encode("utf-8")
    st.download_button(
        "‚¨áÔ∏è Descargar desglose (CSV)",
        data=csv,
        file_name="desglose_items.csv",
        mime="text/csv",
        use_container_width=True,
    )

    # Informe Word (opcional)
    with st.expander("üìÑ Generar informe en Word", expanded=True):
        col1, col2 = st.columns(2)
        docente = col1.text_input("Nombre del docente (opcional)")
        institucion = col2.text_input("Instituci√≥n (opcional)")
        report_bytes = build_docx_report(
            df_items,
            totals,
            meta={"docente": docente, "institucion": institucion},
        )
        nombre_archivo = "Informe_Valorador.docx" if not docente else f"Informe_Valorador_{docente.replace(' ', '_')}.docx"
        st.download_button(
            "‚¨áÔ∏è Descargar informe en Word (.docx)",
            data=report_bytes,
            file_name=nombre_archivo,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True,
        )

    with st.expander("üîß Debug: Conteos detectados", expanded=False):
        st.json(counts)

except PDFSupportMissing:
    st.error(
        "No se pudo leer el PDF porque **pdfplumber** no est√° instalado en esta instancia. "
        "Sub√≠ el CV en **.docx** o **.txt** o agreg√° `pdfplumber` a requirements.txt y reinici√° la app."
    )
except ValueError as ve:
    st.error(str(ve))
except Exception as e:
    st.error(f"Error inesperado: {e}")
